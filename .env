# OctateCode Environment Configuration
# Root level .env file for workspace settings (P2P Backend excluded)
# Generated: January 27, 2026

# ============================================================
# FRONTEND - P2P Collaboration Backend URLs
# ============================================================
# Note: P2P Backend itself uses different env vars (see p2p-backend/.env)
REACT_APP_P2P_HTTP=http://localhost:3000
REACT_APP_P2P_WS=ws://localhost:3001

# Window global configuration (set in frontend at runtime)
# These are exposed to the frontend via window.__COLLABORATION_*__
# REACT_APP_COLLABORATION_BACKEND_URL=http://localhost:3000
# REACT_APP_COLLABORATION_BACKEND_HOST=localhost:3000
# REACT_APP_COLLABORATION_WS_URL=ws://localhost:3001
# REACT_APP_APP_URL=http://localhost:8080

# ============================================================
# NODE.JS / BUILD ENVIRONMENT
# ============================================================
NODE_ENV=development

# VS Code Development
VSCODE_DEV=1
VSCODE_CLI=1
VSCODE_QUALITY=oss
VSCODE_REPOSITORY=${workspaceFolder}
VSCODE_REMOTE_SERVER_PATH=

# Testing
MOCHA_COLORS=1
BUILD_ARTIFACTSTAGINGDIRECTORY=
SNAPSHOT_WORKER_DATA=

# ============================================================
# LLM PROVIDERS - API CREDENTIALS
# ============================================================
# OpenAI
OPENAI_API_KEY=sk-...

# Anthropic
ANTHROPIC_API_KEY=sk-ant-...

# DeepSeek
DEEPSEEK_API_KEY=sk-...

# Google Gemini
GOOGLE_API_KEY=

# Groq
GROQ_API_KEY=

# xAI (Grok)
XAI_API_KEY=

# Mistral
MISTRAL_API_KEY=

# LiteLLM (for multi-provider routing)
LITELLM_API_KEY=
LITELLM_ENDPOINT=http://localhost:4000

# OpenRouter (multi-model aggregator)
OPENROUTER_API_KEY=

# ============================================================
# LOCAL MODEL PROVIDERS
# ============================================================
# Ollama
OLLAMA_ENDPOINT=http://127.0.0.1:11434

# vLLM (Inference Server)
VLLM_ENDPOINT=http://localhost:8000

# LM Studio
LM_STUDIO_ENDPOINT=http://localhost:1234

# ============================================================
# MODEL CONTEXT PROTOCOL (MCP)
# ============================================================
# MCP Servers for tool integration
MCP_SERVER_ENABLED=true
MCP_MEMORY_LIMIT=1024
MCP_TIMEOUT=30000

# ============================================================
# DEVELOPMENT & BUILD
# ============================================================
# React / Browser Build
REACT_APP_ENV=development

# Browser CSP (Content Security Policy)
# For local development with Ollama/vLLM
CSP_REPORT_URI=

# ============================================================
# OPTIONAL - For Future Features
# ============================================================
# Database (if added later)
# DATABASE_URL=
# POSTGRES_URL=
# REDIS_URL=

# Analytics & Monitoring
# SENTRY_DSN=
# ANALYTICS_TOKEN=

# Feature Flags
# FEATURE_COLLABORATION_ENABLED=true
# FEATURE_MCP_ENABLED=true
# FEATURE_FAST_APPLY_ENABLED=true

# ============================================================
# NOTES
# ============================================================
# 1. P2P Backend uses separate .env in p2p-backend/ folder
#    It includes: PORT, SIGNALING_PORT, CORS_ORIGINS, etc.
#
# 2. Provider credentials should be kept secret
#    Don't commit actual API keys to version control
#
# 3. Local providers (Ollama, vLLM, LM Studio) are auto-discovered
#    Update ENDPOINTS only if running on different ports/hosts
#
# 4. Frontend receives config via window.__COLLABORATION_BACKEND_URL__
#    at runtime (set in product.json or index.html)
#
# 5. For production, use environment-specific .env files:
#    .env.production, .env.staging, etc.
